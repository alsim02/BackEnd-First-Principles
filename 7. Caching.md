# Appunti: Caching

## 1. Cos'è il caching
- Il caching è un meccanismo per **ridurre il tempo e lo sforzo** necessari a svolgere un’operazione, mantenendo una copia di un sottoinsieme di dati in una posizione più veloce da accedere.
- Caching permette di diminuire la latenza, ridurre il carico sulle risorse primarie e migliorare le performance delle applicazioni.

## 2. Esempi reali di caching
### Google Search
- L’algoritmo di ricerca è molto complesso e costoso in termini di risorse.
- Queries popolari sono memorizzate in cache in server distribuiti in-memory distribuiti geograficamente.
- Se la query è in cache (cache hit), la risposta è istantanea; altrimenti si calcola e poi si memorizza in cache.

### Netflix e Content Delivery Network (CDN)
- Netflix archivia contenuti (video in varie risoluzioni) in data center principali (originating servers).
- Usa **CDN**: reti di server distribuiti geograficamente vicino agli utenti (edge locations) per ridurre latenza e carico.
- Solo un sottoinsieme dei dati viene cachato negli edge server in base alla domanda locale.
- CDN migliora significativamente la velocità di streaming e scalabilità globale.

### Twitter (X) e trending topics
- Calcolo di trending topics è computazionalmente costoso.
- Risultati calcolati periodicamente e memorizzati in cache in-memory (es. Redis).
- Cache di trending topic viene servita a milioni di utenti in modo rapido.
- Dati non cambiano continuamente, rendendo il caching particolarmente efficace.

## 3. Livelli di caching rilevanti per backend
- **Network level:** CDN, DNS caching.
- **Hardware level:** cache CPU (L1, L2, L3), RAM veloce rispetto a disco.
- **Software level:** caching in memoria tramite database in-memory (es. Redis, Memcached).

## 4. Come funziona il caching nella rete
- CDN distribuiti geograficamente minimizzano latenza servendo contenuti statici più vicino agli utenti.
- DNS caching evita lookup ripetuti su server DNS sparsi nel mondo, mantenendo mappe temporanee di domini-IP per rapido accesso.

## 5. Hardware caching
- Caches L1, L2, L3 nella CPU memorizzano dati frequentemente usati per operazioni veloci.
- RAM (memoria principale) fornisce accesso rapido rispetto a dischi meccanici o SSD.
- In-memory database memorizzano dati nella RAM per performance elevate.

## 6. Tecnologie di caching in-memory
- Redis, Memcached, AWS ElasticCache.
- Si tratta di database key-value ad accesso casuale (random access) in memoria principale.
- Facilità di integrazione con backend tramite librerie specifiche.

## 7. Strategie di caching
- **Lazy caching (cache aside):** la cache è popolata solo quando un dato viene richiesto e mancante (cache miss). Dopo il fetch il dato viene inserito in cache.
- **Write-through caching:** ogni scrittura nel DB primario aggiorna contemporaneamente la cache, mantenendo la cache sempre aggiornata e consistente ma con overhead maggiore.

## 8. Politiche di eviction (scarto dati in cache)
- **No eviction:** nessun dato viene scartato, ma la cache si riempie e restituisce errore.
- **LRU (Least Recently Used):** scarta il dato meno recentemente usato.
- **LFU (Least Frequently Used):** scarta il dato meno frequentemente usato.
- **TTL (Time to Live):** dati scadono dopo un intervallo di tempo definito, eliminati automaticamente.

## 9. Casi d’uso tipici di caching in backend
- Caching di query complesse a database per diminuire carico e latenza.
- Caching di dati statici o a bassa frequenza di aggiornamento (es. dettagli prodotto e profili utente).
- Caching di sessioni utente per velocizzare autenticazione e autorizzazione.
- Caching di risposte di API esterne per limitare chiamate e costi.
- Implementazione di rate limiting usando database in-memory per contare richieste per IP.

---
